{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import anthropic\n",
        "from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n",
        "from anthropic.types.messages.batch_create_params import Request\n",
        "\n",
        "import json\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import functions.prompts as prompts\n",
        "\n",
        "client = anthropic.Anthropic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "ids = []\n",
        "\n",
        "with open(\"fallback.txt\", \"r\") as f:\n",
        "    ids = ast.literal_eval(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"dump/csv/papers.csv\")\n",
        "df['rank'] = df['id'].apply(lambda x: x.split(\"_\")[0])\n",
        "# df = df.loc[df['rank'].isin([\"1\", \"50\", \"100\"])].reset_index(drop=True)\n",
        "# sample 3 papers from each rank with seed 42\n",
        "df = df.groupby('rank').sample(n=3, random_state=42).reset_index(drop=True)\n",
        "# df.head()\n",
        "\n",
        "# get items with id\n",
        "# df = df.loc[df['id'].isin(ids)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def req(id, text, top5=True):\n",
        "    return Request(\n",
        "        custom_id=id,\n",
        "        params=MessageCreateParamsNonStreaming(\n",
        "            model=\"claude-3-5-haiku-20241022\",\n",
        "            max_tokens=1024,\n",
        "            system=f\"{prompts.top5() if top5 else prompts.analysis()}\\nPlease respond in valid JSON format that matches this schema: {str(prompts.Top5Model.model_json_schema() if top5 else prompts.AnalysisModel.model_json_schema())}. **IMPORTANT**: ONLY RESPOND WITH A JSON OBJECT CONTAINING SCORES ACCORDING TO THE ABOVE SCHEMA. THE RESPONSE MUST END WITH A CURLY BRACKET. DO NOT ADD ANALYSIS OR EXPLANATION.\",\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": text\n",
        "            }, {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": \"{\"\n",
        "            }]\n",
        "        )\n",
        "    )\n",
        "    \n",
        "def batch(text, id):\n",
        "    return [req(f\"{id}Z0Qtop5\", text)]\n",
        "    # return [    *[ req(f\"{id}Z{i}Qtop5\", text) for i in range(3) ],\n",
        "    #             *[ req(f\"{id}Z{i}Qanalysis\", text, top5=False) for i in range(3) ] ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "institutions = [\n",
        "       \"Massachusetts Institute of Technology\",\n",
        "       \"Harvard University\",\n",
        "       # \"University of Warwick\",\n",
        "       \"London School of Economics and Political Science\",\n",
        "       # \"University of Tokyo\",\n",
        "       \"University of Cape Town\",\n",
        "       \"Nanyang Technological University\",\n",
        "       \"Chulalongkorn University\",\n",
        "       # \"Universiti Malaya\",\n",
        "   ]\n",
        "\n",
        "top_names = [\n",
        "       \"Andrei Shleifer\", \"Daron Acemoglu\", \"James J. Heckman\",\n",
        "       \"Joseph E. Stiglitz\", \"John List\", \"Carmen M. Reinhart\",\n",
        "       \"Janet Currie\", \"Esther Duflo\", \"Asli Demirguc-Kunt\",\n",
        "       \"Marianne Bertrand\"\n",
        "]\n",
        "\n",
        "\n",
        "# bottom_names = [\n",
        "#        \"Harold Huibing Zhang\", \"Lin Zhou\", \"Andrei Zlate\",\n",
        "#        \"Ulf Zoelitz\", \"Asaf Zussman\", \"Lu Yang\",\n",
        "#        \"Anzelika Zaiceva\", \"Aleksandra Zdzienicka\",\n",
        "#        \"Qiankun Zhou\", \"Vera Zipperer\"\n",
        "# ]\n",
        "\n",
        "\n",
        "random_names = [\n",
        "       \"Bruce S. Green\", \"Alejandro L. James\", \"Billie J. Abels\",\n",
        "       \"Paul A. Jenkins\", \"Gary L. Bodie\", \"Gail J. Doan\",\n",
        "       \"Shirley S. Hodgkins\", \"Pattie K. Reinhardt\",\n",
        "       \"Tara R. Weber\", \"Tabitha J. Cox\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_req = {}\n",
        "divider = 1\n",
        "for i in range(divider):\n",
        "    full_req[f'batch-{i}'] = []\n",
        "\n",
        "# .iloc[np.r_[0:4, -4:0]]\n",
        "\n",
        "t_names = [\"top\", \"bot\", \"ran\"]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    file_index = math.floor(index / (len(df) / divider))\n",
        "    with open(f'output/{row[\"id\"]}.txt', 'r') as f:\n",
        "        text = f.read()\n",
        "        \n",
        "        \n",
        "        for ind, ins in enumerate(institutions):\n",
        "            paper = f\"PAPER TITLE: {row['name']}\\n\\nAFFILIATION: {ins}\\n\\nPAPER TEXT: {text}\"\n",
        "            full_req[f\"batch-{file_index}\"] += batch(paper, row[\"id\"]+f\"Iins{ind}\")\n",
        "            \n",
        "        for ind, names in enumerate([top_names, random_names]):\n",
        "            for ind2, name in enumerate(names):\n",
        "                paper = f\"PAPER TITLE: {row['name']}\\n\\nAUTHOR: {name}\\n\\nPAPER TEXT: {text}\"\n",
        "                full_req[f\"batch-{file_index}\"] += batch(paper, row[\"id\"]+f\"I{t_names[ind]}{ind2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(divider):\n",
        "    print(len(full_req[f'batch-{i}']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_req[f'batch-0'][5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KINDA DANGEROUS\n",
        "batches = []\n",
        "for i in range(divider):\n",
        "    print(f\"Sending Batch {i}\")\n",
        "    message_batch = client.messages.batches.create(\n",
        "        requests=full_req[f'batch-{i}'])\n",
        "    print(f\"{i} {message_batch.id}\")\n",
        "    batches.append(message_batch)\n",
        "\n",
        "print(batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "id = \"msgbatch_01SRPGUnpmdEZNrYBGYBygGN\"\n",
        "def wait(id):\n",
        "    results = client.messages.batches.retrieve(id).processing_status\n",
        "    while results == \"in_progress\":\n",
        "        stat = client.messages.batches.retrieve(id)\n",
        "        print(stat.request_counts)\n",
        "        results = stat.processing_status\n",
        "        time.sleep(5)\n",
        "\n",
        "wait(id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batches = []\n",
        "with open(\"dump/anthropic-batch/anthropic-batch-bias.txt\", 'r') as f:\n",
        "    batches = f.read()\n",
        "    batches = batches.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parsed = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_r(r):\n",
        "    id = r.custom_id\n",
        "    validateModel = prompts.AnalysisModel if \"analysis\" in id else prompts.Top5Model\n",
        "    try:\n",
        "        text = r.result.message.content[0].text\n",
        "        text = \"{\" + text.split(\"}\")[0] + \"}\"\n",
        "\n",
        "        return {\n",
        "            \"id\": id,\n",
        "            \"scores\": validateModel.model_validate(json.loads(text)).model_dump()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error {e} - {\"{\" + r.result.message.content[0].text}\")\n",
        "        return {\n",
        "            \"id\": id,\n",
        "            \"scores\": None\n",
        "        }\n",
        "\n",
        "for b in batches:\n",
        "    results = client.messages.batches.results(b)\n",
        "    for r in results:\n",
        "        if(r and r.result.type == 'succeeded'):\n",
        "            try:\n",
        "                if(r.custom_id not in parsed):\n",
        "                    x = parse_r(r)\n",
        "                    with open('dump/eval-output/anthropic-result-bias.jsonl', 'a') as f:\n",
        "                        f.write(json.dumps(parse_r(r)) + \"\\n\")\n",
        "                    parsed.add(r.custom_id)\n",
        "            except Exception as e:\n",
        "                print(\"ERROR! - \" + str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv(\"dump/csv/papers.csv\")\n",
        "\n",
        "f = open('dump/eval-output/anthropic-result-bias.jsonl', 'r')\n",
        "file_response = f.read()\n",
        "f.close()\n",
        "\n",
        "for line in file_response.split(\"\\n\")[:-1]:\n",
        "    l = json.loads(line)\n",
        "    id, bias = l['id'].split(\"Z\")[0].split(\"I\")\n",
        "    no, typ = l['id'].split(\"Z\")[1].split(\"Q\")\n",
        "    \n",
        "    # print(id)\n",
        "    \n",
        "    idx = df.index[df['id'] == id].tolist()[0]\n",
        "\n",
        "    # content = l['response']['body']['choices'][0]['message']['content']\n",
        "    \n",
        "    metrics = ['score'] if typ == \"top5\" else ['originality', 'rigor', 'scope', 'impact', 'written_by_ai']\n",
        "    validateModel = prompts.Top5Model if typ == \"top5\" else prompts.AnalysisModel\n",
        "    \n",
        "\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        column_name = f\"anthropic-{bias}-{metric}-{int(no)+1}\"\n",
        "        \n",
        "        if column_name not in df.columns:\n",
        "            df[column_name] = None\n",
        "\n",
        "        o = validateModel.model_validate(l['scores'])\n",
        "        df.loc[idx, column_name] = o.__dict__[metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df['rank'] = df['id'].apply(lambda x: x.split(\"_\")[0])\n",
        "df.loc[df['id']  == \"56_5\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"dump/csv/bias_a.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"dump/anthropic-batch/anthropic-batch-bias.txt\", 'r') as f:\n",
        "    batches = f.read()\n",
        "    batches = batches.split(\"\\n\")\n",
        "    \n",
        "    for b in batches:\n",
        "        results = client.messages.batches.results(b)\n",
        "        for r in results:\n",
        "            if(r and r.result.type != 'succeeded'):\n",
        "                print(r.custom_id)\n",
        "                # try:\n",
        "                #     x = parse_r(r)\n",
        "                #     with open('dump/eval-output/anthropic-result-bias.jsonl', 'a') as f:\n",
        "                #         f.write(json.dumps(parse_r(r)) + \"\\n\")\n",
        "                # except Exception as e:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
