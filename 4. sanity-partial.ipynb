{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n",
    "from anthropic.types.messages.batch_create_params import Request\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import functions.prompts as prompts\n",
    "\n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"dump/csv/papers.csv\")\n",
    "df['rank'] = df['id'].apply(lambda x: x.split(\"_\")[0])\n",
    "df = df.loc[df['rank'].isin([\"1\", \"25\", \"50\", \"75\", \"100\"])].reset_index(drop=True)\n",
    "\n",
    "len(df)\n",
    "\n",
    "# random -> only real paper / is not in 1/25/50/75/100 -> sample n=10\n",
    "# rand = df[:-100].loc[~df['rank'].isin([\"1\", \"25\", \"50\", \"75\", \"100\"])].sample(n=10, random_state=42)\n",
    "\n",
    "# sample = pd.concat([ranks, rand]).reset_index(drop=True)\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req(id, text, top5=True):\n",
    "    return Request(\n",
    "        custom_id=id,\n",
    "        params=MessageCreateParamsNonStreaming(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=1024,\n",
    "            system=f\"{prompts.top5() if top5 else prompts.analysis()}\\nPlease respond in valid JSON format that matches this schema: {str(prompts.Top5Model.model_json_schema() if top5 else prompts.AnalysisModel.model_json_schema())}. **IMPORTANT**: ONLY RESPOND WITH AN JSON OBJECT CONTAINING SCORES ACCORDING TO THE ABOVE SCHEMA. THE RESPONSE MUST END WITH A CURLY BRACKET. DO NOT ADD ANALYSIS OR EXPLANATION.\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }, {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"{\"\n",
    "            }]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "def batch(text, id):\n",
    "    return [    *[ req(f\"{id}Z{i}Qtop5\", text) for i in range(3) ],\n",
    "                *[ req(f\"{id}Z{i}Qanalysis\", text, top5=False) for i in range(3) ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_req = {}\n",
    "divider = 1\n",
    "for i in range(divider):\n",
    "    full_req[f'batch-{i}'] = []\n",
    "\n",
    "def partial(paper, no):\n",
    "    l = len(paper.split())\n",
    "    # if(no == 0.01):\n",
    "        # print(\"asdf\", math.ceil((l * no) / 100))\n",
    "    return \" \".join(paper.split()[:math.ceil((l * no) / 100)])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    file_index = math.floor(index / (len(df) / divider))\n",
    "    with open(f'output/{row[\"id\"]}.txt', 'r') as f:\n",
    "        text = f.read()\n",
    "        paper = f\"PAPER TITLE: {row['name']}\\n\\nPAPER TEXT: {text}\"\n",
    "        \n",
    "        for no in [0.1, 1, 10, 50, 100]:\n",
    "            full_req[f\"batch-{file_index}\"] += batch(partial(paper, no), row[\"id\"]+\"P\"+str(no).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "for i in range(divider):\n",
    "    print(len(full_req[f'batch-{i}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': '1_0P1Z1Qanalysis',\n",
       " 'params': {'model': 'claude-3-5-haiku-20241022',\n",
       "  'max_tokens': 1024,\n",
       "  'system': 'Please evaluate the attached research according to the following criteria.\\n\\nORIGINALITY\\n\"In your capacity as an editorial board/reviewer for this paper, please rate this paper’s originality. Note that papers with high originality typically address questions of broad, foundational importance or propose groundbreaking methodologies. They often set new standards in the field or open new research avenues. \\n (0 = Completely unoriginal, …, 10 = Completely original)”\\n\\nRIGOR\\n\"In your capacity as an editorial board/reviewer for this paper, please rate this paper’s rigor. Note that papers that are rigorous are those in which the data handling and analysis process is highly transparent, with all steps carefully documented (0 = Not at all rigorous, …, 10 = Extremely rigorous)”\\n\\nSCOPE\\n\"In your capacity as an editorial board/reviewer for this paper, please rate this paper’s scope. Note that papers that have a narrow scope are those that focus on narrower questions or less generalisable findings, which, while still valuable, may not have the same broad impact (0 = Very narrow scope, …, 10 = Very wide scope)”\\n\\nIMPACT\\n\"In your capacity as an editorial board/reviewer for this paper, please rate this paper’s impact. Note that papers with high impact have clear implications for public policy or major economic debates, making their findings influential beyond academia. (0 = Minimal impact, …, 10 = Maximum impact)”\\n\\nWRITTEN_BY_AI\\n\"Please determine whether this paper was written by AI (0 = Definitely human-written, …, 10 = Definitely AI-generated)”\\n\\nPlease respond in valid JSON format that matches this schema: {\\'properties\\': {\\'originality\\': {\\'title\\': \\'Originality\\', \\'type\\': \\'integer\\'}, \\'rigor\\': {\\'title\\': \\'Rigor\\', \\'type\\': \\'integer\\'}, \\'scope\\': {\\'title\\': \\'Scope\\', \\'type\\': \\'integer\\'}, \\'impact\\': {\\'title\\': \\'Impact\\', \\'type\\': \\'integer\\'}, \\'written_by_ai\\': {\\'title\\': \\'Written By Ai\\', \\'type\\': \\'integer\\'}}, \\'required\\': [\\'originality\\', \\'rigor\\', \\'scope\\', \\'impact\\', \\'written_by_ai\\'], \\'title\\': \\'AnalysisModel\\', \\'type\\': \\'object\\'}. **IMPORTANT**: ONLY RESPOND WITH AN JSON OBJECT CONTAINING SCORES ACCORDING TO THE ABOVE SCHEMA. THE RESPONSE MUST END WITH A CURLY BRACKET. DO NOT ADD ANALYSIS OR EXPLANATION.',\n",
       "  'messages': [{'role': 'user',\n",
       "    'content': 'PAPER TITLE: The Political Economy of Zero-Sum Thinking PAPER TEXT: THE This paper offers a strategic rationale for zero-sum thinking in elections. We show that asymmetric information and distributional considerations together make voters wary of policies supported by others. This force impels a majority of voters to support policies contrary to their preferences and information. Our analysis identiﬁes and in- terprets a form of “adverse correlation” that is necessary and sufﬁcient for zero-sum thinking to prevail in equilibrium. 1. INTRODUCTION ZERO-SUM THINKING approaches policy decisions with the mindset that gains that accrue to some parties necessarily come at the expense of others. A remarkable feature of this worldview is that it manifests even in non zero-sum choices, where one policy is widely regarded to beneﬁt voters on average. For instance, experts see the immigration of skilled labor as spurring economic growth and innovation, creating a larger tax base, and even leading to greater employment of those native-born through complementarities and'},\n",
       "   {'role': 'assistant', 'content': '{'}]}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_req[f'batch-{i}'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending Batch 0\n",
      "0 msgbatch_01MWaRLXaNoCnT1QTMtTx1Ec\n",
      "[MessageBatch(id='msgbatch_01MWaRLXaNoCnT1QTMtTx1Ec', archived_at=None, cancel_initiated_at=None, created_at=datetime.datetime(2025, 3, 25, 18, 8, 49, 649326, tzinfo=datetime.timezone.utc), ended_at=None, expires_at=datetime.datetime(2025, 3, 26, 18, 8, 49, 649326, tzinfo=datetime.timezone.utc), processing_status='in_progress', request_counts=MessageBatchRequestCounts(canceled=0, errored=0, expired=0, processing=1500, succeeded=0), results_url=None, type='message_batch')]\n"
     ]
    }
   ],
   "source": [
    "# KINDA DANGEROUS\n",
    "batches = []\n",
    "for i in range(divider):\n",
    "    print(f\"Sending Batch {i}\")\n",
    "    message_batch = client.messages.batches.create(\n",
    "        requests=full_req[f'batch-{i}'])\n",
    "    print(f\"{i} {message_batch.id}\")\n",
    "    batches.append(message_batch)\n",
    "\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "id = \"msgbatch_01MWaRLXaNoCnT1QTMtTx1Ec\"\n",
    "def wait(id):\n",
    "    results = client.messages.batches.retrieve(id).processing_status\n",
    "    while results == \"in_progress\":\n",
    "        stat = client.messages.batches.retrieve(id)\n",
    "        print(stat.request_counts)\n",
    "        results = stat.processing_status\n",
    "        time.sleep(5)\n",
    "\n",
    "wait(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "with open(\"dump/anthropic-batch/anthropic-batch-partial.txt\", 'r') as f:\n",
    "    batches = f.read()\n",
    "    batches = batches.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_r(r):\n",
    "    id = r.custom_id\n",
    "    validateModel = prompts.Top5Model if \"top5\" in id else prompts.AnalysisModel\n",
    "    try:\n",
    "        text = r.result.message.content[0].text\n",
    "        text = \"{\" + text.split(\"}\")[0] + \"}\"\n",
    "        return {\n",
    "            \"id\": id,\n",
    "            \"scores\": validateModel.model_validate(json.loads(text)).model_dump()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} - {\"{\" + r.result.message.content[0].text}\")\n",
    "        return {\n",
    "            \"id\": id,\n",
    "            \"scores\": None\n",
    "        }\n",
    "\n",
    "for b in batches:\n",
    "    results = client.messages.batches.results(b)\n",
    "    for r in results:\n",
    "        if(r and r.result.type == 'succeeded'):\n",
    "            try:\n",
    "                with open('dump/eval-output/anthropic-result-partial.jsonl', 'a') as f:\n",
    "                    f.write(json.dumps(parse_r(r)) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(\"ERROR! - \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dump/csv/segments.csv\")\n",
    "\n",
    "f = open('dump/eval-output/anthropic-result-partial.jsonl', 'r')\n",
    "file_response = f.read()\n",
    "f.close()\n",
    "\n",
    "for line in file_response.split(\"\\n\")[:-1]:\n",
    "    l = json.loads(line)\n",
    "    id, s = l['id'].split(\"Z\")[0].split(\"P\")\n",
    "    no, typ = l['id'].split(\"Z\")[1].split(\"Q\")\n",
    "    \n",
    "    idx = df.index[df['id'] == id].tolist()[0]\n",
    "    \n",
    "    # content = l['response']['body']['choices'][0]['message']['content']\n",
    "    \n",
    "    metrics = ['score'] if typ == \"top5\" else ['originality', 'rigor', 'scope', 'impact', 'written_by_ai']\n",
    "    validateModel = prompts.Top5Model if typ == \"top5\" else prompts.AnalysisModel\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        column_name = f\"anthropic-{s}-{metric}-{int(no)+1}\"\n",
    "        \n",
    "        if column_name not in df.columns:\n",
    "            df[column_name] = None\n",
    "\n",
    "        o = validateModel.model_validate(l['scores'])\n",
    "        df.loc[idx, column_name] = o.__dict__[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>file</th>\n",
       "      <th>name</th>\n",
       "      <th>journal</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>len-original</th>\n",
       "      <th>len-anond</th>\n",
       "      <th>rank</th>\n",
       "      <th>anthropic-0-score-1</th>\n",
       "      <th>...</th>\n",
       "      <th>anthropic-100-originality-2</th>\n",
       "      <th>anthropic-100-rigor-2</th>\n",
       "      <th>anthropic-100-scope-2</th>\n",
       "      <th>anthropic-100-impact-2</th>\n",
       "      <th>anthropic-100-written_by_ai-2</th>\n",
       "      <th>anthropic-100-originality-3</th>\n",
       "      <th>anthropic-100-rigor-3</th>\n",
       "      <th>anthropic-100-scope-3</th>\n",
       "      <th>anthropic-100-impact-3</th>\n",
       "      <th>anthropic-100-written_by_ai-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>1. Econometrica/ecta200736.pdf</td>\n",
       "      <td>The Political Economy of Zero-Sum Thinking</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>S. Nageeb Ali; Maximilian Mihm; Lucas Siga</td>\n",
       "      <td>Department of Economics, Pennsylvania State Un...</td>\n",
       "      <td>16496.0</td>\n",
       "      <td>15956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>1. Econometrica/ecta200731.pdf</td>\n",
       "      <td>Social Media and Collective Action in China</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>Bei Qin; David Strömberg; Yanhui Wu</td>\n",
       "      <td>Bei Qin: Department of Accountancy, Economics ...</td>\n",
       "      <td>18206.0</td>\n",
       "      <td>17419.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_2</td>\n",
       "      <td>1. Econometrica/ecta200725.pdf</td>\n",
       "      <td>Ambiguous Contracts</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>Paul Dütting; Michal Feldman; Daniel Peretz; L...</td>\n",
       "      <td>Google Research; School of Computer Science, T...</td>\n",
       "      <td>11830.0</td>\n",
       "      <td>11448.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_3</td>\n",
       "      <td>1. Econometrica/ecta200741.pdf</td>\n",
       "      <td>PERSUASION MEETS DELEGATION</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>Anton Kolotilin; Andriy Zapechelnyuk</td>\n",
       "      <td>Anton Kolotilin: School of Economics, UNSW Bus...</td>\n",
       "      <td>15756.0</td>\n",
       "      <td>15075.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_4</td>\n",
       "      <td>1. Econometrica/Econometrica - 2025 - Berger -...</td>\n",
       "      <td>Minimum Wages, Efficiency, and Welfare</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>David Berger; Kyle Herkenhoff; Simon Mongey</td>\n",
       "      <td>Economics Department, Duke University; Departm...</td>\n",
       "      <td>18607.0</td>\n",
       "      <td>16735.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               file  \\\n",
       "0  1_0                     1. Econometrica/ecta200736.pdf   \n",
       "1  1_1                     1. Econometrica/ecta200731.pdf   \n",
       "2  1_2                     1. Econometrica/ecta200725.pdf   \n",
       "3  1_3                     1. Econometrica/ecta200741.pdf   \n",
       "4  1_4  1. Econometrica/Econometrica - 2025 - Berger -...   \n",
       "\n",
       "                                          name       journal  \\\n",
       "0   The Political Economy of Zero-Sum Thinking  Econometrica   \n",
       "1  Social Media and Collective Action in China  Econometrica   \n",
       "2                          Ambiguous Contracts  Econometrica   \n",
       "3                  PERSUASION MEETS DELEGATION  Econometrica   \n",
       "4       Minimum Wages, Efficiency, and Welfare  Econometrica   \n",
       "\n",
       "                                             authors  \\\n",
       "0         S. Nageeb Ali; Maximilian Mihm; Lucas Siga   \n",
       "1                Bei Qin; David Strömberg; Yanhui Wu   \n",
       "2  Paul Dütting; Michal Feldman; Daniel Peretz; L...   \n",
       "3               Anton Kolotilin; Andriy Zapechelnyuk   \n",
       "4        David Berger; Kyle Herkenhoff; Simon Mongey   \n",
       "\n",
       "                                        affiliations  len-original  len-anond  \\\n",
       "0  Department of Economics, Pennsylvania State Un...       16496.0    15956.0   \n",
       "1  Bei Qin: Department of Accountancy, Economics ...       18206.0    17419.0   \n",
       "2  Google Research; School of Computer Science, T...       11830.0    11448.0   \n",
       "3  Anton Kolotilin: School of Economics, UNSW Bus...       15756.0    15075.0   \n",
       "4  Economics Department, Duke University; Departm...       18607.0    16735.0   \n",
       "\n",
       "  rank anthropic-0-score-1  ... anthropic-100-originality-2  \\\n",
       "0    1                   2  ...                           8   \n",
       "1    1                   2  ...                           9   \n",
       "2    1                   2  ...                           8   \n",
       "3    1                   3  ...                           8   \n",
       "4    1                   2  ...                           9   \n",
       "\n",
       "  anthropic-100-rigor-2 anthropic-100-scope-2 anthropic-100-impact-2  \\\n",
       "0                     9                     9                      9   \n",
       "1                    10                     9                     10   \n",
       "2                     9                     9                      8   \n",
       "3                     9                     9                      8   \n",
       "4                    10                     9                      8   \n",
       "\n",
       "  anthropic-100-written_by_ai-2 anthropic-100-originality-3  \\\n",
       "0                             1                           8   \n",
       "1                             1                           9   \n",
       "2                             1                           9   \n",
       "3                             1                           8   \n",
       "4                             1                           9   \n",
       "\n",
       "  anthropic-100-rigor-3 anthropic-100-scope-3 anthropic-100-impact-3  \\\n",
       "0                     9                     9                     10   \n",
       "1                    10                     9                     10   \n",
       "2                    10                     9                      8   \n",
       "3                     9                     9                      8   \n",
       "4                    10                     9                      9   \n",
       "\n",
       "  anthropic-100-written_by_ai-3  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             1  \n",
       "3                             1  \n",
       "4                             0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rank'] = df['id'].apply(lambda x: x.split(\"_\")[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dump/csv/result_partial.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
